user {{ nginx_user }};
worker_processes {{ nginx_worker_processes }};
worker_priority 15;

events {
    worker_connections {{ nginx_worker_connections }};
    #accept_mutex on;
}

http {
    types_hash_max_size 2048;
    server_names_hash_bucket_size 64;


    client_body_timeout         3000;
    client_header_timeout       28;
    keepalive_timeout           28 28;
    send_timeout                28;
    client_max_body_size        1000M;

    ssl_protocols               {{ nginx_ssl_protocols }};
    ssl_ciphers                 {{ nginx_ssl_ciphers  }};
    ssl_prefer_server_ciphers   on;
    ssl_session_timeout         1d;
    ssl_session_cache           shared:SSL:50m;
    ssl_dhparam                 /etc/ssl/certs/dhparam.pem;
    # ssl_stapling                on;
    # ssl_stapling_verify         on;

    ## General Options
    charset                     utf-8; # adds the line "Content-Type" into response-header, same as "source_charset"
    default_type                application/octet-stream;

    gzip                        on;
    #gzip_vary                  on;  # send response header "Vary: Accept-Encoding"
    gzip_proxied                any;  # enables compression for any request
    gzip_disable                "msie6";
    gzip_comp_level             1;
    gzip_buffers                16 8k;
    gzip_http_version           1.0;
    gzip_types                  text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;
    ignore_invalid_headers      on;
    keepalive_requests          50;  # number of requests per connection, does not affect SPDY
    keepalive_disable           none; # allow all browsers to use keepalive connections
    max_ranges                  0;   # disabled to stop range header DoS attacks
    msie_padding                off;
    #open_file_cache            max=1000 inactive=2h;
    #open_file_cache_errors     on;
    #open_file_cache_min_uses   1;
    #open_file_cache_valid      1h;
    #output_buffers             1 512;
    postpone_output             1440;   # postpone sends to match our machine's MSS
    read_ahead                  512K;   # kernel read head set to the output_buffers
    recursive_error_pages       on;
    reset_timedout_connection   on;  # reset timed out connections freeing ram
    sendfile                    on;  # on for decent direct disk I/O
    server_tokens               off; # version number in error pages
    server_name_in_redirect     off; # if off, nginx will use the requested Host header
    source_charset              utf-8; # same value as "charset"
    tcp_nodelay                 on; # Nagle buffering algorithm, used for keepalive only
    tcp_nopush                  off;

    include mime.types;
    include {{ nginx_prefix }}/sites-enabled/*;

    ##
    # Logging Settings
    ##

    # access_log {{ nginx_http_log_path }};
    # error_log {{ nginx_error_log_path }} error;

    ## Proxy settings. Make sure the "timeout"s are long enough to
    ## take account of over loaded back end servers or long running
    ## cgi scripts. If the proxy timeout is too short the nginx proxy
    ## might re-request the data over and over again, putting more
    ## load on the backend server.
    proxy_max_temp_file_size    0;
    proxy_connect_timeout       900;
    proxy_send_timeout          900;
    proxy_read_timeout          900;
    proxy_buffer_size           4k;
    proxy_buffers               4 32k;
    proxy_busy_buffers_size     64k;
    proxy_temp_file_write_size  64k;
    proxy_intercept_errors      on;

    server {
        listen 80 default_server;
        server_name "";
        return 444;
    }
}
